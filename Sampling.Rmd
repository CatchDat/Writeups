---
title: "Sampling Methods for Synthetic Population Generation"
author: "Andrew P Smith and Robin Lovelace"
date: "`r Sys.Date()`"
output: pdf_document
vignette: >
  %\VignetteIndexEntry{Quasirandom Sampling for Microsimulation}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
bibliography: ref.bib
---

autoNumber: all

```{r, eval=FALSE}
# Get bibliography (run once from project root)
u = "https://www.zotero.org/api/groups/418217/collections/MP7NS3SC/items/top?limit=100&format=bibtex&v=1"
b = httr::GET(url = u, httr::write_disk("ref.bib", overwrite = T))
```

The R package **synthpop** provides a set of tools for generating synthetic data, in the context of anonymisation rather than modelling [@nowok_synthpop:_2016]. ...

@kavroudakis_sms:_2015 focus on the spatial variability of individual-level dat.

## Abstract

The established numerical methods for synthesising a population from marginal data are robust and well understood, but none are able to generate an integral population. Thus some postprocessing ("integerisation") may need to be done to remove fractional values. The motivation for this work was to investigate possible alternative methods of synthesis that are computationally fast and directly result in integral populations. We show that, not unexpectedly, quasirandom numbers are much better than pseudorandom numbers at sampling a valid population, but there is no guarantee of convergence. Secondly, we demonstrate that sampling the marginals without replacement does guarantee convergence, but may result in population that are statistically unlikely. We present the latter algorithm the open-source R package `humanleague`, which interested readers are invited to evaluate.

## Introduction

Raking is considered to be a solved problem. However current methods do have some shortfalls, for example generating fractional populations, and can be computationally intensive. W

## Theory

### Quasirandom Numbers

Quasirandom numbers, often referred to as low discrepancy sequences, are preferential to pseudorandom numbers in many applications, despite not having some of the (appearance of) randomness properties of (good) pseudorandom generators. In this work we focus on the Sobol QRNG of (refs Sobol, Bratley and Fox, Joe & Kuo). 

Quasi: inherent dimension, no independence, faster convergence.  
Pseudo: dimensionless, (appear to be) independent, slower convergence.

Sobol sequences used for e.g. numerical integration will converge at a rate of $\approx1/N$ (actually $(ln N)^D/N$ ref Numerical Recipes) compared to $\sim1/\sqrt N$ for a PRNG, and thuis require far fewer samples to achieve the same level of accuracy.

If we consider the sample space to be a multivariate discrete distribution over the unit hypercube, this maps directly to the values of the Sobol sequence.


### Sampling without Replacement


### The Algorithm

A mathematical statement of the microsimulation problem is as follows:

(NB In the notation below, the index $i$ is scalar and refers to a particular dimension. The index $\mathbf{k}$ is a vector index $[k_1, k_2,...k_D]$ of length $D$, the dimensionality of the problem.)

Given a population $P$ and a set of $N$ marginal vectors $\mathbf{m}_i$ of length $l_i$ such that we have $S$ possible states

$$S=\prod\limits_{i}l_i$$

Find a contingency table $\mathbf T$ in N dimensions such that

$$\sum\limits_{\mathbf{k}, k_i fixed} \mathbf{T}_\mathbf{k} = \mathbf{m}_i$$

in other words each element of $\mathbf{m}_i$ is the sum of all elements in $\mathbf{T}$ for a fixed value of $k_i$.

Each marginal sum must equal the population $P$:

$$\sum\limits \mathbf{m}_{i} = P$$ (2)

as must the sum of the elements of contingency table:

$$\sum\limits_\mathbf{k} \mathbf{T} = P$$ (3)

and finally we constrain the elements to the natural numbers: 

$${\mathbf{T} \in \mathbb{N}^S,\mathbf{m}_i} \in \mathbb{N}^{l_i}$$ (4)

In the general case this is an ill-posed problem as there are not enough constraints for a unique solution. Hence the need to resort to iterative or optimisation-type solutions, such as IPF, simulated annealing, maximum likelihood, chi-squared fitting, least-squares fitting.



## Method

### A Worked Example

We consider a 2 dimensional case here for simpilicity, for a population of 100 consisting of 51 females and 49 males, of which 35 are aged under 0-29, 40 aged 30-59, 25 aged 60+. Thus our constraint vectors are: $\mathbf{m}_0=[51,49]$ and $\mathbf{m}_1=[35,40,25]$ and there are 6 possible states.    

We construct a bivariate discrete distibution using the marginals which will have a probability density

$$p_{ij} = \frac{(\mathbf{m}_0)_i(\mathbf{m}_1)_j}{\sum\limits_i\mathbf{m}_0\sum\limits_j\mathbf{m}_1}$$ (8)

We take 100 (i.e. the population) random samples $(i,j)$ from this distribution to create a seed population $\mathbf{T}$ (in bold), which for example may look like:

 $\mathbf{m}_0\setminus\mathbf{m}_1$ |  35    | 40     | 25     | $\mathbf{r}_0$
:-----------------------------------:|--------|--------|--------|----
            51                       | **19** | **20** | **11** | *-1*
            49                       | **17** | **20** | **13** | *+1*
        $\mathbf{r}_1$               |  *+1*  |  *0*  |  *-1*   |

Summing over rows and columns we see we do not quite match the marginals. The residuals (italic, from equation 5) are $\mathbf{r}_0=[-1, 1]$ and $\mathbf{r}_1=[1,0,-1]$.

To correct the population we subtract $\mathbf{r}_0$ from any one column (in this case no choice of column will result in a negative value). Selecting the first column, the population becomes:

 $\mathbf{m}_0\setminus\mathbf{m}_1$ |  35    | 40     | 25     | $\mathbf{r}_0$
:-----------------------------------:|--------|--------|--------|----
            51                       | **20** | **20** | **11** | *0*
            49                       | **16** | **20** | **13** | *0*
        $\mathbf{r}_1$               |  *+1*  |  *0*  |  *-1*   |
    
which now matches $\mathbf{m}_0$. Next we subtract $\mathbf{r}_1$ from the any one row (again no choice of row will result in a negative value). Selecting the first row, the population becomes:

 $\mathbf{m}_0\setminus\mathbf{m}_1$ |  35    | 40     | 25     | $\mathbf{r}_0$
:-----------------------------------:|--------|--------|--------|----
            51                       | **19** | **20** | **12** | *0*
            49                       | **16** | **20** | **13** | *0*
        $\mathbf{r}_1$               |  *0*   |  *0*   |  *0*   |

which results in a population that now matches both marginals. 

### The R Package

We took the Sobol QRNG implementation (in `C`) of stevengj of MIT [https://github.com/stevengj/nlopt/], and put it into a `C++` wrapper that is compliant with the native `C++11` standard library random functionality. We wrote custom N-dimensional array, indexing and iterator functionality, and the QIPF algorithm itself. Finally, using `Rcpp`, we put this into an open source `R` package called `humanleague` which is available at [https://github.com/CatchDat/humanleague](https://github.com/CatchDat/humanleague)

This package supports dimensionality up to 12, although this limit is arbitrary and could be increased if necessary. Input is simply a list of marginal vectors

Output is broadly compatible with the `mipfp` package: N-D population array, number of attempts, variation from "smooth" non-integral solution.

### Testing

#### QRNG vs PRNG

We recorded the success rate of the algorithm for a number of problems using marginals of length 5, comparing the number of attempt required using a good-quality PRNG (MT19937 seed for reproducibility?) instead of the Sobol QRNG.

The test problems ranged from dimensionality 2 to 5, all marginals identical of length 5 in each dimension. As a proxy measure of difficulty we recorded the mean population per state $P/S$. We limited the number of attempts to 1000, and consider that if this limit is reached the algorithm is unlikely to find a solution in any reasonable time.

We present the mean number of attempts (averaged over 100 runs) required to generate a valid population:

Problem 1: $P/S=10$, average attempts to get valid solution ('-' denotes no valid solution found in 1000 attempts)

   Dim   |  2     |  3     | 4     | 5
:-------:|--------|--------|-------|------
    QRNG | **1**  | **1**  | **1** | **1**
    PRNG | **3.4**| **322**| **-** | **-**

Problem 2: $P/S=1$, average attempts to get valid solution

   Dim   |  2     |  3     | 4     | 5
:-------:|--------|--------|-------|------
    QRNG |**6.6** |**1.9** |**4.6**|**7.8**
    PRNG |**470** |**-**   |**-**  | **-**


Problem 3: unevenly distributed marginals $m=[5,25,125,25,5]$, indentical in each dimension. As dimensionality increases, population becomes increasingly sparse:

   Dim   |  2     |  3     | 4     | 5
:-------:|--------|--------|-------|------
    $P/S$|   7.4  |  1.5   |  0.30  |  0.059
    QRNG |**1.05**|**1.3** |**3.4**|**23.5**
    PRNG |**23** |**647**   |**-** | **-**

TODO add ipfp to this comparison

TODO real-world example(s)

## Results

Clearly QRNG makes this method work.

ref Mark/Robin paper(s)

## Discussion

Pros:
Integer domain only (although marginals may need to be integerised)
Fast
Multiple solutions
Deals reasonably well with sparse problems

Cons:
Doesnt always find a solution (but multiple attempts)
Do we have any real estimate of entropy? Is such a thing possible or make sense? Could you infer distributions by generating large numbers of populations? 
Sobol maximum dimensionality in our implementation is 1111. Convergence properties of Sobol worsen with increasing dimension which is likely to increasingly problematic when $D>\approx40$



## Conclusion

## Acknowledgements
stevengj @ MIT for Sobol `C` implementation

